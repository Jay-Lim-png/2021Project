# 4.1 전처리

- what is corpus?

: 자연어처리에 사용하는, 단어들로 이루어진 문장이 코퍼스이다. 코퍼스는 단일 언어 코퍼스와 이중 언어 코퍼스, 다중 언어 코퍼스로 나눌 수 있음. 병렬 코퍼스는 번역데이터처럼 한 문장에 대해 두 개 이상의 언어로 쓰여진 것을 의미.

e.g) 나는 학교에 가는 것을 좋아한다.

## 1. 전처리 과정의 개요

===전처리 순서 ====

1. 코퍼스 수집
2. 정제
3. 문장 단위 분절
4. 분절
5. 병렬 코퍼스 정렬 (생략 가능)
6. 서브워드 분절

## 

## 2. 정제 과정

### [정규표현식]

- or 표현 [ ] : [2345cde]  또는 (2|3|4|5|c|d|e)
- 연속된 숫자 또는 알파벳 표현 [-] : [2-5c-e]
- Not 표현 [^]

    [^2-5c-e] → 2부터 5까지, c부터 2까지를 제외한 한 글자 

- 그룹 만들기 ( ) : 그룹은 수식에서 ( ) 와 비슷한 역할이라고 생각하면 됨.. ( a + b ) * 5 로 반복 표현을 간단하게 할 수 있는 것처럼, 정규표현식에서의 그룹도 비슷한 역할 수행
- ? : 앞의 수식하는 부분이 나타나지 않거나 한 번만 나타날 때

    그룹에서 ?는 다른 역할을 수행하게 됨

- + : 앞의 수식하는 부분이 한 번 이상 나타날 때

    x+

    ![4%201%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20dd78093b37ee45779959c3e1a52657e0/Untitled.png](4%201%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20dd78093b37ee45779959c3e1a52657e0/Untitled.png)

- * : 앞의 수식하는 부분이 나타나지 않거나 여러 번 나타날 경우 (이 말을 처음 읽었을 땐 이런 생각이 들었다. ~~그럼 이러든 저러든 상관 없다는 소리 아니야?~~ 뒤에 예시에서 보겠지만 \S와 함께 사용하면서 '있을 수도 있고 없을 수도 있는 문자'를 처리하기 위해서 사용한다. )
- 반복되는 문자 표현
    - x{n} : x가 9번 반복
    - x{n, } : x가 9번 이상 반복
    - x{n,m} : x가 n번에서 m번 사이를 반복
- . 사용 : 어떤 글자도 지칭할 수 있는 표현 (like 루미큐브 조커카드)

![4%201%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20dd78093b37ee45779959c3e1a52657e0/Untitled%201.png](4%201%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20dd78093b37ee45779959c3e1a52657e0/Untitled%201.png)

정규식 안에서 .을 사용하려면  \. 으로 지정해야 함. 아래 관련문서 참조[https://stackoverflow.com/questions/13989640/regular-expression-to-match-a-dot](https://stackoverflow.com/questions/13989640/regular-expression-to-match-a-dot)

- ^와 $ : [ ] 안에 포함되지 않은 ^와 $는 라인의 시작과 끝을 의미함

    ^x$

    ![4%201%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20dd78093b37ee45779959c3e1a52657e0/Untitled%202.png](4%201%20%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20dd78093b37ee45779959c3e1a52657e0/Untitled%202.png)

- 지정문자 사용

[지정문자 ](https://www.notion.so/b0566cd7b6074ad0adb10204f06765f8)

### 정규식 패턴 연습 사이트

[RegexOne - Learn Regular Expressions - Lesson 1: An Introduction, and the ABCs](https://regexone.com/)

### 파이썬에서 정규 표현식 사용하기

re 모듈을 이용해 파이썬에서 활용

```python
import re
regex_pattern = '^a...s$'  #문장의 처음과 끝이 a와 s로 끝나고, 그 사이에 3개의 문자를 포함 
text = 'abyss'

## re 모듈 함수를 통해 텍스트 전처리
re.sub(regex_pattern, 'REPLACED', text)
>> 'REPLACED'
```

re 모듈의 내장함수는 아래 문서를 참조

[https://www.programiz.com/python-programming/regex](https://www.programiz.com/python-programming/regex)

### 치환자 사용

그룹( ) 으로 지정된 부분을 역슬래시\ 또는 $ + 숫자 형식으로 변수명처럼 가리킬 수 있음

```python
x = '''abcdefg
12345
ab12
ab1bc2d
12ab
a1b
1a
hijklmnop
'''

regex_pattern = r'([a-z])[0-9]+([a-z])'
to = r'\1\2'

y = '\n'.join([re.sub(regex_pattern, to, x_i) for x_i in x.split('\n')])
```

위 코드는 x를 엔터 단위로 나눈 단어들에서 *문자(a-z)*와 *문자(a-z)* 사이의 숫자[0-9]가 있을 경우 문자만 남기도록 단어를 바꿔주었다. 

바뀐 후의 단어인 r'\1\2'에서 \1은 첫번째 그룹인 문자(a-z)를 지칭, \2는 두번째 그룹 ([a-z])를 지칭한다. 

## 3. 문장 단위 분절 과정

마침표만을 기준으로 문장 단위 분절을 수행하면 영어 약자나 소수점 등 여러가지 문제에 마주칠 수 있음. 따라서 분절을 위한 모듈을 만들거나 자연어처리 툴킷인 NLTK를 이용

[문장 단위 분절 예제]

자연어처리는 인공지능의 한 줄기 입니다. 시퀀스 투 시퀀스의 등장 이후로 딥러닝을 활용한 자연어처리는 새로운 전기를 맞이하게 되었습니다. 문장을 받아 단순히 수치로 나타내던 시절을 넘어, 원하는대로 문장을 만들어낼 수 있게 된 것입니다.

```python
import sys, fileinput, re
from nltk.tokenize import sent_tokenize

if __name__ == "__main__":
    for line in fileinput.FileInput('nlp with pytorch chap4.txt'):
        if line.strip() !="": #line.strip() -> 공백을 지우고 문자열을 반환
            line = re.sub(r'([a-z])\.([A-Z])',r'\1. \2', line.strip())
            
            sentences = sent_tokenize(line.strip())
            
        for s in sentences:
            if s!= "":
                sys.stdout.write(s + "\n")
```

위 코드는 [a-z]와 [a-z] 사이에 . 이 있으면 해당 문자열을 [a-z]. [a-z]로 반환한다. 내가 이해하기로는 문장 말미에 마침표를 찍고 띄어쓰기를 하는 문장이 있고, 하지 않는 문장이 있어서 전부 한 칸 띄워주는 걸로 바꾸는 것 같다. 혹은 sent_tokenize가 마침표+띄어쓰기만 문장 단위로 인식한다거나?

찾아보니 sent_tokenize는 regular expression을 이용하는 Treebank tokenizer 방법을 사용한다. 이 Treebank tokenizer는 텍스트가 이미 문장 단위로 분리되어있다고 가정한다. 

[문장 합치기 예제]

자연어처리는 인공지능의 한 줄기 입니다. 시퀀스 투 시퀀스의 등장 이후로 \n
딥러닝을 활용한 자연어처리는 새로운 전기를 맞이하게 되었습니다. 문장을\n
받아 단순히 수치로 나타내던 시절을 넘어, 원하는대로 문장을 만들어낼 수 \n
있게 된 것입니다.

```python
import sys, fileinput
from nltk.tokenize import sent_tokenize

if __name__ == "__main__":
    buf = []

    for line in fileinput.input(data):
        if line.strip() != "":
            buf += [line.strip()]
            sentences = sent_tokenize(" ".join(buf))

            if len(sentences) > 1:
                buf = sentences[1:]

                sys.stdout.write(sentences[0] + '\n')

    sys.stdout.write(" ".join(buf) + "\n")
```

위 코드는 문장을 하나로 합친 뒤에, sent_tokenize를 이용하여 이번에는 제대로 된 문장 단위로 분리해주게 된다. 

## 4. 단어 단위의 분절

[한국어 분절]

전형적인 문장에서는 프로그램마다 성능이 비슷하지만, 신조어나 고유명사를 처리할 때 신조어마다 처리 정책이 다르다. 따라서 본인이 가진 텍스트의 성질을 잘 파악하여 프로그램을 선택해야 함

- Mecab

    : 가장 속도가 빠름

    윈도우에서는 사용이 불가능함

    설치는 아래 참조

    [설치하기 - KoNLPy 0.4.3 documentation](https://konlpy-ko.readthedocs.io/ko/v0.4.3/install/#ubuntu)

- KoNLPy

    내부 라이브러리들이 각기 다른 언어로 이루어져 호환성 문제가 발생하거나, 일부 라이브러리들이 자바로 구현되어 Mecab에 비해 대용량 코퍼스 처리에 불리함 (속도 이슈)

    그러나 설치가 자유로워 널리 이용

    각 KoNLPy 하위 클래스의 특징은 아래를 참조

    [tag Package - KoNLPy 0.5.2 documentation](https://konlpy.org/ko/latest/api/konlpy.tag/#module-konlpy.tag._hannanum)